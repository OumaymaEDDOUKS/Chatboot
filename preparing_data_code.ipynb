{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_kMPGOPR176",
        "outputId": "68ebc758-cbbc-4696-8272-4a9b50c5bdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQdbZewfTjT_",
        "outputId": "b5936d92-6ea7-431b-f118-26fafe782baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-4.20.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.8.5)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro==1.8.2 (from cohere)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.16.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.7.22)\n",
            "Installing collected packages: fastavro, backoff, cohere\n",
            "Successfully installed backoff-2.2.1 cohere-4.20.2 fastavro-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install cohere\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms3wj7S1TjVz",
        "outputId": "2c3bf791-c12b-47be-ec7f-536ec6b6ce90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/232.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgIslRCYxFrp",
        "outputId": "e4e66bd1-8edd-47a7-e42b-d3e68df87034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading pdf: <_io.BufferedReader name='/content/drive/MyDrive/one_arti_1/4.pdf'>\n",
            "This pdf has 17 pages\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import PyPDF2\n",
        "import textwrap\n",
        "\n",
        "\"\"\"\n",
        "This code iterates over a list of PDFs, extracts text, and divides it into chunks. Then it saves the chunks into a JSON file.\n",
        "\"\"\"\n",
        "\n",
        "pdf_dir = os.path.join(os.getcwd(), '/content/drive/MyDrive/one_arti_1')\n",
        "json_file = os.path.join('/content/drive/MyDrive/kenz', 'data4.json')\n",
        "\n",
        "\n",
        "pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
        "\n",
        "output = []\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    with open(os.path.join(pdf_dir, pdf_file), \"rb\") as f:\n",
        "        pdf_reader = PyPDF2.PdfReader(f)\n",
        "        print(f'Reading pdf: {f}')\n",
        "        num_pages = len(pdf_reader.pages)\n",
        "        print(f'This pdf has {num_pages} pages')\n",
        "        for page_num in range(num_pages):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            content = page.extract_text()\n",
        "            chunks = textwrap.wrap(content, 1000)\n",
        "\n",
        "            for chunk in chunks:\n",
        "                output.append({\n",
        "                    \"filename\": pdf_file,\n",
        "                    \"page_number\": page_num + 1,\n",
        "                    \"content\": chunk\n",
        "                })\n",
        "\n",
        "with open(json_file, \"w\") as f:\n",
        "    json.dump(output, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "fo6avO8gXOoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import cohere\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "co = cohere.Client('GUMF9oMInIPQrGS1kZVtUtI488P5NOwBBiiwdiYJ')\n",
        "\n",
        "# Load existing JSON data from the file\n",
        "with open(\"/content/drive/MyDrive/kenz/data4.json\", \"r\") as json_file:\n",
        "    passages_data = json.load(json_file)\n",
        "\n",
        "# Initialize the list to store the generated QA pairs\n",
        "generated_qa_pairs = []\n",
        "\n",
        "for entry in passages_data:\n",
        "    # Keep generating until the answer_start is greater than 0\n",
        "    while True:\n",
        "        try:\n",
        "            context = entry[\"content\"]\n",
        "            paper_name = entry[\"filename\"]\n",
        "            print(f'Trying this passage: {context[:100]}')\n",
        "\n",
        "            response = co.generate(\n",
        "                model='command',\n",
        "                prompt=f'Generate five questions (not multiple-choice) related to the following passage. Each question must have its answer in the passage and be in the format:\\n\\n{{ \"question\": \"\", \"answer\": \"\" }}\\n\\nPassage: {context}\\n\\nQuestion:',\n",
        "                max_tokens=300,\n",
        "                temperature=0.7,\n",
        "                k=0,\n",
        "                stop_sequences=[],\n",
        "                return_likelihoods='NONE'\n",
        "            )\n",
        "\n",
        "            generated_text = response.generations[0].text.strip()\n",
        "\n",
        "            parts = re.split(r\"Réponse:|Answer:|reponse:|answer:|Reponse:|réponse:\", generated_text)\n",
        "            if len(parts) == 2:\n",
        "                generated_question = parts[0].strip()\n",
        "                generated_answer = parts[1].strip()\n",
        "            else:\n",
        "                generated_question = generated_text\n",
        "                generated_answer = \"\"\n",
        "\n",
        "\n",
        "\n",
        "            answer_start = context.find(generated_answer)\n",
        "\n",
        "            # Check the condition and regenerate if needed\n",
        "            if answer_start == 0:\n",
        "\n",
        "                print(\"Regenerating QA pair...\")\n",
        "                continue\n",
        "            else:\n",
        "                print(answer_start)\n",
        "                break  # Exit the loop if the condition is satisfied\n",
        "\n",
        "        except cohere.error.CohereAPIError:\n",
        "            print('Cohere API error. Waiting for 65 seconds before retrying...')\n",
        "            time.sleep(65)\n",
        "            continue\n",
        "\n",
        "    qa_pair = {\n",
        "        \"paragraphs\": [\n",
        "            {\n",
        "                \"context\": context,\n",
        "                \"qas\": [\n",
        "                    {\n",
        "                        \"question\": generated_question,\n",
        "                        \"id\": str(uuid.uuid4()),\n",
        "                        \"answers\": [\n",
        "                            {\n",
        "                                \"text\": generated_answer,\n",
        "                                \"answer_start\": answer_start\n",
        "                            }\n",
        "\n",
        "                        ]\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    print(qa_pair)\n",
        "\n",
        "    generated_qa_pairs.append(qa_pair)\n",
        "\n",
        "    print(\"QA pair generated.\")\n",
        "\n",
        "# Write the generated QA pairs to a JSON file\n",
        "output_path = os.path.join('/content/drive/MyDrive/kenz', 'qa_dataset4.json')\n",
        "\n",
        "with open(output_path, \"w\") as json_file:\n",
        "    json.dump(generated_qa_pairs, json_file, indent=4)\n",
        "\n",
        "print(\"All QA pairs generated and added to the JSON dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoesK7IqPhgU",
        "outputId": "34453c65-30ea-4481-e9fd-50f40f638039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying this passage: Longformer: The Long-Document Transformer Iz Beltagy\u0003Matthew E. Peters\u0003Arman Cohan\u0003 Allen Institute \n",
            "-1\n",
            "{'paragraphs': [{'context': 'Longformer: The Long-Document Transformer Iz Beltagy\\x03Matthew E. Peters\\x03Arman Cohan\\x03 Allen Institute for Artiﬁcial Intelligence, Seattle, WA, USA fbeltagy,matthewp,armanc g@allenai.org Abstract Transformer-based models are unable to pro- cess long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer’s attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task moti- vated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language mod- eling and achieve state-of-the-art results on text8 andenwik8 . In contrast to most prior work, we also pretrain Longformer and ﬁnetune it on a variety of downstream tasks.', 'qas': [{'question': 'What is the name of the organization that Iz Beltagy, Matthew E. Peters, Arman Cohan, Allen Institute for Artificial Intelligence belong to?', 'id': 'f1faa893-754b-4d1d-a56b-47f888437443', 'answers': [{'text': 'Allen Institute for Artiﬂcial Intelligence, Seattle, WA, USA', 'answer_start': -1}]}]}]}\n",
            "QA pair generated.\n",
            "Trying this passage: Our pretrained Longformer consistently out- performs RoBERTa on long document tasks and sets new sta\n",
            "Regenerating QA pair...\n",
            "Trying this passage: Our pretrained Longformer consistently out- performs RoBERTa on long document tasks and sets new sta\n",
            "Regenerating QA pair...\n",
            "Trying this passage: Our pretrained Longformer consistently out- performs RoBERTa on long document tasks and sets new sta\n",
            "Cohere API error. Waiting for 65 seconds before retrying...\n",
            "Trying this passage: Our pretrained Longformer consistently out- performs RoBERTa on long document tasks and sets new sta\n",
            "234\n",
            "{'paragraphs': [{'context': 'Our pretrained Longformer consistently out- performs RoBERTa on long document tasks and sets new state-of-the-art results on Wiki- Hop and TriviaQA. We ﬁnally introduce the Longformer-Encoder-Decoder (LED), a Long- former variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv sum- marization dataset.1 1 Introduction Transformers (Vaswani et al., 2017) have achieved state-of-the-art results in a wide range of natu- ral language tasks including generative language modeling (Dai et al., 2019; Radford et al., 2019) and discriminative language understanding (De- vlin et al., 2019). This success is partly due to the self-attention component which enables the net- work to capture contextual information from the entire sequence. While powerful, the memory and computational requirements of self-attention grow \\x03Equal contribution. 1https://github.com/allenai/longformer Figure 1: Runtime and memory of full self- attention and', 'qas': [{'question': 'Which of the following is not a task that the Longformer can be used for?', 'id': '969f239e-989a-4ca7-bd58-fb4bf43092c7', 'answers': [{'text': 'supporting long document generative sequence-to-sequence tasks', 'answer_start': 234}]}]}]}\n",
            "QA pair generated.\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Regenerating QA pair...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Regenerating QA pair...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Regenerating QA pair...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Regenerating QA pair...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Regenerating QA pair...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Regenerating QA pair...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Regenerating QA pair...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Regenerating QA pair...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Cohere API error. Waiting for 65 seconds before retrying...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Regenerating QA pair...\n",
            "Trying this passage: different implementations of Long- former’s self-attention; Longformer-loop is non- vectorized, Long\n",
            "Cohere API error. Waiting for 65 seconds before retrying...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gBFey7_h1bk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z3mRGkT31bna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXolFIv81bqe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}